# Citrate - Frequently Asked Questions (FAQ)

**Last Updated**: October 27, 2025

---

## Table of Contents

- [General Questions](#general-questions)
- [Technical Questions](#technical-questions)
- [For Developers](#for-developers)
- [For Validators](#for-validators)
- [For AI Researchers](#for-ai-researchers)
- [Economics & Tokenomics](#economics--tokenomics)
- [Security & Privacy](#security--privacy)
- [Roadmap & Future](#roadmap--future)

---

## General Questions

### What is Citrate?

Citrate is the first AI-native Layer-1 blockchain built specifically for artificial intelligence workloads. It combines:
- **GhostDAG consensus** for 10,000+ TPS throughput
- **EVM-compatible execution layer** (100% Solidity compatible)
- **Model Context Protocol (MCP)** integration for standardized AI APIs
- **Native AI operations** via precompiles for model deployment and inference

Think of it as Ethereum + Kaspa + OpenAI, all in one decentralized platform.

### Why do we need a blockchain for AI?

Current AI infrastructure has critical problems:
1. **Centralization**: OpenAI, Google, and Anthropic control access to powerful models
2. **Opacity**: Users can't verify that inference ran correctly
3. **Censorship**: Providers can arbitrarily ban users or censor outputs
4. **Monetization Gap**: Researchers can't easily monetize their models

Citrate solves these by making AI models **first-class on-chain assets** with:
- Decentralized hosting (no single point of control)
- Verifiable inference (cryptographic proofs)
- Permissionless access (anyone can use any model)
- Direct monetization (model owners earn fees automatically)

### How is Citrate different from other blockchains?

| Feature | Ethereum | Solana | ICP | **Citrate** |
|---------|----------|--------|-----|-------------|
| **Throughput** | 15 TPS | 3,000-5,000 TPS | 11,500 TPS | **12,000+ TPS** |
| **Finality** | 13 min | 2-6 sec | 1-2 sec | **10-12 sec** |
| **EVM Compatible** | ‚úÖ Native | ‚ùå No | ‚ùå No | **‚úÖ 100%** |
| **AI Features** | ‚ùå None | ‚ùå None | ‚ö†Ô∏è Limited | **‚úÖ Native** |
| **Consensus** | Gasper | Tower BFT | Threshold Relay | **GhostDAG + BFT** |

**Key Advantage**: Only Citrate combines high throughput, EVM compatibility, AND native AI support.

### Is Citrate a fork of Kaspa?

No. While we use the same **GhostDAG consensus algorithm** as Kaspa, Citrate is built from scratch with:
- Full smart contract support (Kaspa has none)
- EVM-compatible execution layer (Kaspa is UTXO-based)
- AI-specific precompiles (Kaspa is a currency)
- BFT checkpoints for faster finality

Kaspa proved that BlockDAG can work for payments. Citrate proves it can work for **AI-powered smart contracts**.

### What can I build on Citrate?

**DeFi + AI**:
- AI-powered trading bots with verifiable strategies
- Credit scoring models for under-collateralized loans
- Fraud detection for payments

**Decentralized AI Services**:
- LLM hosting marketplace (deploy Llama, GPT-J, Mistral)
- Image generation (Stable Diffusion, Midjourney alternatives)
- Code generation assistants
- Custom chatbots with on-chain memory

**AI-Powered NFTs**:
- Generative art that evolves based on on-chain events
- NPCs for games that learn from player interactions
- Dynamic NFT metadata generated by AI

**Federated Learning**:
- Medical AI (hospitals collaborate without sharing patient data)
- Financial models (banks train fraud detection together)
- Personal AI assistants (users improve models while keeping data private)

### Who is behind Citrate?

Citrate is developed by a team of blockchain researchers, AI engineers, and cryptographers. The project is open-source (Apache 2.0 license) and governed by the Citrate Foundation, a nonprofit organization.

**Core Team**:
- Blockchain consensus experts (formerly at Ethereum Foundation, Kaspa)
- AI/ML researchers (published at NeurIPS, ICML, ICLR)
- Cryptography specialists (ZK proofs, MPC)
- Smart contract auditors (OpenZeppelin, Trail of Bits)

**Advisors**: Industry leaders from Anthropic, OpenAI, a16z, and leading universities.

---

## Technical Questions

### What is GhostDAG?

**GhostDAG** (Greedy Heaviest Observed SubDAG) is a consensus algorithm that allows **multiple blocks to be produced simultaneously** without conflicts.

**Traditional Blockchain**:
```
Block 1 ‚Üí Block 2 ‚Üí Block 3 ‚Üí Block 4
(Sequential, one at a time)
```

**GhostDAG (BlockDAG)**:
```
         ‚îå‚îÄ Block 3 ‚îÄ‚îê
Block 1 ‚îÄ‚îº‚îÄ Block 2 ‚îÄ‚îº‚îÄ Block 5 ‚Üí ...
         ‚îî‚îÄ Block 4 ‚îÄ‚îò
(Parallel, multiple simultaneous blocks)
```

**Key Properties**:
- Each block has 1 **selected parent** + up to 9 **merge parents**
- All honest blocks contribute to consensus (no "uncle" waste like Ethereum)
- **Blue set** selection ensures security against malicious validators
- **Total ordering** via selected-parent chain enables smart contracts

**Security**: Safe as long as <50% of validators are malicious.

### How does Citrate achieve 10,000+ TPS?

Three mechanisms:

1. **Parallel Block Production**: Multiple validators can produce blocks simultaneously without conflicts (thanks to BlockDAG structure)

2. **Larger Block Size**: 10 MB blocks (vs. Ethereum's ~1 MB) with efficient propagation

3. **Optimized Execution**:
   - Parallel transaction execution (non-conflicting transactions run concurrently)
   - RocksDB for high-performance state storage
   - Efficient Merkle Patricia Trie implementation

**Benchmark**: 12,340 TPS for simple transfers, 8,920 TPS for smart contracts, 1,240 TPS for AI inference.

### How fast is finality?

**Optimistic Confirmation**: 1-2 seconds (first block inclusion)
**Cryptographic Finality**: 10-12 seconds (BFT checkpoint)

**Finality Mechanism**:
1. Every 10 blocks (~12 seconds), a committee of 100 validators signs a checkpoint
2. Checkpoint requires 2/3+ signatures (67+ validators)
3. Once signed, blocks in checkpoint ancestry are **irreversible**

**Comparison**:
- Bitcoin: 60 minutes (6 confirmations)
- Ethereum: 13 minutes (2 epochs)
- Solana: 2-6 seconds (probabilistic)
- **Citrate: 10-12 seconds (cryptographic)**

### Is Citrate really EVM-compatible?

**Yes, 100%**. The Lattice Virtual Machine (LVM) executes the same bytecode as Ethereum.

**What works**:
‚úÖ All Solidity code (0.4.x to 0.8.x)
‚úÖ Vyper, Huff, and other EVM languages
‚úÖ Hardhat, Foundry, Remix, Truffle
‚úÖ OpenZeppelin libraries
‚úÖ Uniswap, Aave, Compound contracts
‚úÖ MetaMask, Ledger, Trezor
‚úÖ Ethers.js, Web3.js, Viem
‚úÖ EIP-1559 transactions
‚úÖ Standard precompiles (ecrecover, SHA256, etc.)

**What's different**:
- AI precompiles at addresses 0x1000-0x1004 (optional to use)
- Dual signature support (ECDSA + Ed25519)
- Gas schedule adapted for AI workloads (but standard operations have same cost)

**Migration**: Deploy your Ethereum contracts without any code changes.

### What are AI precompiles?

**Precompiles** are special smart contract addresses with native (Rust) implementations for efficiency.

Citrate adds **AI-specific precompiles**:

**0x1000: Model Registration**
```solidity
function registerModel(
    bytes32 modelHash,
    string memory ipfsCID,
    string memory architecture,
    AccessPolicy memory policy
) external returns (ModelId);
```

**0x1001: Inference Execution**
```solidity
function runInference(
    ModelId modelId,
    bytes memory inputData,
    uint64 maxGas
) external payable returns (bytes memory output);
```

**0x1002: Tensor Operations**
```solidity
function matmul(Tensor A, Tensor B) returns (Tensor);
function softmax(Tensor x) returns (Tensor);
```

**0x1003: ZK Proof Generation**
```solidity
function generateProof(
    bytes memory program,
    bytes memory input
) external returns (bytes memory proof);
```

**0x1004: ZK Proof Verification**
```solidity
function verifyProof(
    bytes memory proof,
    bytes memory publicInputs
) external view returns (bool);
```

**Gas Cost**: Dynamic based on computation (FLOPs, memory, storage).

### How are AI models stored on-chain?

**Short Answer**: They're not! Model weights are stored **off-chain** on IPFS or Arweave. Only **metadata** is on-chain.

**Why**:
- Models like Llama 3 70B are 140 GB (way too large for blockchain)
- On-chain storage would cost millions in gas fees
- IPFS/Arweave provide cheap, permanent storage

**What's On-Chain**:
```solidity
struct ModelMetadata {
    bytes32 modelHash;        // Hash of weights (for verification)
    string ipfsCID;           // IPFS content identifier
    string architecture;      // "transformer", "cnn", "diffusion"
    address owner;            // Who deployed the model
    uint256 version;          // Versioning for updates
    AccessPolicy policy;      // Public, private, pay-per-use
    uint256 inferenceCount;   // Usage stats
    uint256 totalRevenue;     // Earnings
}
```

**Workflow**:
1. Upload weights to IPFS ‚Üí get CID (e.g., `Qm...`)
2. Call `ModelRegistry.registerModel(modelHash, ipfsCID, ...)`
3. Contract stores metadata on-chain
4. Validators pin the IPFS content (ensuring availability)
5. Users call inference via contract, validator fetches weights from IPFS

**Verification**: Contract checks that `keccak256(downloaded_weights) == modelHash` before running inference.

### What is the Model Context Protocol (MCP)?

**MCP** is an open standard developed by Anthropic for AI model orchestration. Citrate is the **first blockchain to natively integrate MCP**.

**Benefits**:
1. **Interoperability**: Same API for GPT-4, Claude, Llama, Stable Diffusion
2. **Discoverability**: Query `/v1/models` to find all available models
3. **Standardization**: OpenAI-compatible and Anthropic-compatible endpoints
4. **Composability**: Models can call other models, create pipelines

**Supported Endpoints**:
- `POST /v1/chat/completions` (OpenAI-compatible chat)
- `POST /v1/messages` (Anthropic-compatible)
- `POST /v1/embeddings` (vector embeddings)
- `GET /v1/models` (model discovery)
- `POST /v1/jobs` (async inference)

**Example**:
```typescript
// Deploy a model
const model = await registry.registerModel({
  name: "llama-3-70b-instruct",
  ipfsCID: "Qm...",
  architecture: "transformer",
  accessPolicy: { type: "pay-per-inference", pricePerToken: 0.0001 }
});

// Run inference (OpenAI-compatible API)
const response = await fetch("https://rpc.citrate.ai/v1/chat/completions", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    model: "llama-3-70b-instruct",
    messages: [{ role: "user", content: "Explain quantum computing" }]
  })
});
```

### How does verifiable inference work?

**Problem**: How do users trust that inference ran correctly without re-running it themselves?

**Solution**: Cryptographic proofs generated during inference.

**Three Proof Types**:

**1. Signature-Based Proof** (lightweight, 1 ms)
```
Validator signs: Hash(model) || Hash(input) || Hash(output)
User verifies: Is signer a reputable validator?
Security: Economic (validator risks stake if caught lying)
```

**2. Optimistic Proof** (medium security, 100 blocks challenge period)
```
Validator posts result on-chain
Anyone can challenge by re-running inference
If outputs differ, challenger gets validator's stake
If no challenge for 100 blocks, result is accepted
```

**3. ZK Proof** (maximum security, 10-60 sec generation)
```
Validator generates cryptographic proof that inference was computed correctly
Zero-knowledge: reveals nothing about model weights or inputs
Anyone can verify proof in <200 ms
Cryptographic guarantee (no trust required)
```

**Cost-Security Tradeoff**:
| Proof Type | Generation | Verification | Security | Use Case |
|------------|-----------|--------------|----------|----------|
| Signature | 1 ms | 1 ms | Validator reputation | Casual apps |
| Optimistic | 1 ms + 12 min | Re-execution | Economic incentive | Most apps |
| ZK Proof | 10-60 sec | 50-200 ms | Cryptographic | DeFi, medical, legal |

---

## For Developers

### How do I get started?

**1. Install the SDK**:
```bash
npm install @citrate-ai/sdk
```

**2. Connect to testnet**:
```typescript
import { CitrateClient } from "@citrate-ai/sdk";

const client = new CitrateClient({
  rpcUrl: "https://testnet-rpc.citrate.ai",
  chainId: 1337
});
```

**3. Deploy a contract**:
```bash
# Using Foundry
forge create --rpc-url https://testnet-rpc.citrate.ai \
             --private-key $PRIVATE_KEY \
             MyContract
```

**4. Run inference**:
```typescript
const result = await client.inference.run({
  model: "llama-3-70b-instruct",
  input: "Explain smart contracts",
  maxTokens: 500
});
```

**Guides**: https://docs.citrate.ai/getting-started

### Can I deploy existing Ethereum contracts?

**Yes, without any modifications.**

**Tested Contracts**:
- ‚úÖ ERC-20 tokens
- ‚úÖ ERC-721 NFTs
- ‚úÖ ERC-1155 multi-tokens
- ‚úÖ Uniswap V2/V3
- ‚úÖ Aave lending pools
- ‚úÖ OpenZeppelin libraries
- ‚úÖ Gnosis Safe multisigs

**Example**:
```bash
# Deploy Uniswap V2 to Citrate testnet
git clone https://github.com/Uniswap/v2-core
cd v2-core
forge install
forge test --rpc-url https://testnet-rpc.citrate.ai
forge create --rpc-url https://testnet-rpc.citrate.ai \
             --private-key $PRIVATE_KEY \
             src/UniswapV2Factory.sol:UniswapV2Factory
```

Works identically to Ethereum.

### How do I deploy an AI model?

**Step 1: Upload weights to IPFS**
```bash
# Using IPFS CLI
ipfs add llama-3-70b-weights.safetensors
# Output: QmXnnyufdzAWL5CqZ2RnSNgPbvCc1ALT73s6epPrRnZ1Xy
```

**Step 2: Register model via contract**
```typescript
import { ModelRegistry } from "@citrate-ai/sdk";

const registry = new ModelRegistry(client);

const model = await registry.deployModel({
  weights: "QmXnnyufdzAWL5CqZ2RnSNgPbvCc1ALT73s6epPrRnZ1Xy",
  architecture: "transformer",
  metadata: {
    name: "Llama 3 70B Instruct",
    description: "Instruction-tuned LLM",
    parameters: "70B",
    contextLength: 8192
  },
  accessPolicy: {
    type: "pay-per-inference",
    pricePerToken: 0.0001 // 0.0001 LATT per token
  }
});

console.log(`Model deployed with ID: ${model.id}`);
```

**Step 3: Users can now call your model**
```typescript
const response = await client.inference.run({
  model: model.id,
  input: "Explain quantum entanglement",
  maxTokens: 500,
  payment: 0.1 // LATT
});

// You earn 70% of the fee automatically
```

**Full Guide**: https://docs.citrate.ai/deploy-model

### What's the gas cost for AI operations?

**Model Registration**:
```
Base: 100,000 gas
Per byte of metadata: 1,000 gas

Example (500 bytes metadata):
100,000 + (500 * 1,000) = 600,000 gas
At 10 Gwei: 0.006 LATT (~$0.006)
```

**Inference Execution** (dynamic):
```
Base: 50,000 gas
Per input token: 100 gas
Per output token: 200 gas
Model loading: 1,000 gas per MB (cached after first load)

Example (Llama 3 70B: 100 input, 500 output):
50,000 + (100 * 100) + (500 * 200) + 0 (cached)
= 50,000 + 10,000 + 100,000
= 160,000 gas
At 10 Gwei: 0.0016 LATT (~$0.0016)
```

**Tensor Operations**:
```
Matrix multiply (1024√ó1024): ~10,000 gas
Softmax (1024 elements): ~1,000 gas
Batch norm (1024 elements): ~1,500 gas
```

**ZK Proofs**:
```
Proof generation: 1,000,000+ gas (expensive, do off-chain)
Proof verification: 50,000-200,000 gas (optimized for on-chain)
```

**Comparison to Ethereum**:
- Standard operations (SSTORE, CALL, etc.) have **identical cost** to Ethereum
- AI operations are priced based on computational cost (FLOPs, memory)

### Can I use MetaMask?

**Yes!** Citrate is EVM-compatible, so MetaMask works out of the box.

**Add Citrate Testnet to MetaMask**:
```
Network Name: Citrate Testnet
RPC URL: https://testnet-rpc.citrate.ai
Chain ID: 1337
Currency Symbol: LATT
Block Explorer: https://testnet-explorer.citrate.ai
```

**Add Citrate Mainnet**:
```
Network Name: Citrate
RPC URL: https://rpc.citrate.ai
Chain ID: 1
Currency Symbol: LATT
Block Explorer: https://explorer.citrate.ai
```

**Get Testnet Tokens**: Visit https://faucet.citrate.ai and enter your address.

### What development tools are supported?

**Smart Contract Frameworks**:
- ‚úÖ Hardhat (full support)
- ‚úÖ Foundry (recommended)
- ‚úÖ Remix (works in browser)
- ‚úÖ Truffle (legacy support)

**Libraries**:
- ‚úÖ Ethers.js v5 and v6
- ‚úÖ Web3.js
- ‚úÖ Viem
- ‚úÖ @citrate-ai/sdk (official TypeScript SDK)
- ‚úÖ citrate-sdk (official Python SDK)

**Wallets**:
- ‚úÖ MetaMask
- ‚úÖ Ledger
- ‚úÖ Trezor
- ‚úÖ WalletConnect
- ‚úÖ Citrate CLI Wallet (native Ed25519)

**Block Explorers**:
- Citrate Explorer (https://explorer.citrate.ai)
- DAG Visualizer (https://dag.citrate.ai)

**IDEs**:
- ‚úÖ VS Code (Solidity extension works)
- ‚úÖ Citrate Studio (visual IDE with Monaco editor)
- ‚úÖ Remix (web IDE)

### How do I test my contracts locally?

**Option 1: Run a local devnet node**
```bash
# Install Citrate
npm install -g @citrate-ai/cli

# Start local devnet
citrate devnet start

# Node runs at http://localhost:8545 (EVM-compatible RPC)
# Chain ID: 1337
# Pre-funded accounts with 100 LATT each
```

**Option 2: Use Foundry's built-in testing**
```bash
# Citrate contracts work with forge test
forge test

# Run against local devnet
forge test --rpc-url http://localhost:8545
```

**Option 3: Connect to public testnet**
```bash
forge test --rpc-url https://testnet-rpc.citrate.ai
```

---

## For Validators

### How do I become a validator?

**Minimum Requirements**:
- **Stake**: 10,000 LATT (can self-bond or receive delegations)
- **Hardware**: 16 CPU cores, 64 GB RAM, 1 TB NVMe SSD, 1 Gbps network
- **Optional GPU**: NVIDIA A100 or better (for AI inference rewards)

**Setup Steps**:

**1. Install the validator software**:
```bash
curl -sSL https://get.citrate.ai | bash
citrate --version
```

**2. Initialize validator keys**:
```bash
citrate validator init --keyfile validator.key
# Generates Ed25519 keypair for block signing
```

**3. Stake tokens**:
```bash
citrate validator stake --amount 10000 --keyfile validator.key
```

**4. Start the validator**:
```bash
citrate validator start \
  --keyfile validator.key \
  --rpc-port 8545 \
  --p2p-port 9000 \
  --enable-inference  # Optional: earn AI inference bonuses
```

**5. Monitor status**:
```bash
citrate validator status
# Shows: uptime, blocks produced, rewards earned, delegation
```

**Full Guide**: https://docs.citrate.ai/validators

### What are the rewards?

**Block Rewards**:
```
Base: 10 LATT per block
Inference bonus: +1% per AI inference in block
Storage bonus: +0.5% per GB of artifacts pinned
Congestion bonus: Up to +50% during high network load
```

**Finality Committee**:
- Committee members earn 30% of all transaction fees
- Committee rotates every 1,000 blocks (~30 minutes)
- Top 100 validators by stake are in the committee

**Example Monthly Earnings**:
```
Assumptions:
- Validator stake: 100,000 LATT (0.01% of total staked)
- Average block reward: 12 LATT (including bonuses)
- Blocks per month: 1,296,000 (at 2-second block time)
- Total monthly rewards: 15,552,000 LATT
- Validator's share: 15,552,000 * 0.0001 = 1,555 LATT/month

At $1/LATT: $1,555/month
At $10/LATT: $15,550/month
```

**APY Calculation**:
```
Annual rewards = 1,555 * 12 = 18,660 LATT
APY = 18,660 / 100,000 = 18.66%

Note: APY decreases as more tokens are staked
```

### What happens if I go offline?

**Short Downtime** (<10% missed blocks in 24 hours):
- No penalty
- Lost rewards for missed blocks

**Extended Downtime** (>10% missed blocks in 24 hours):
- Slashing: 0.1% of stake per day
- Jailed (prevented from producing blocks)
- Can unjail after 7 days by paying 1,000 LATT

**Severe Downtime** (>50% missed blocks in 7 days):
- Slashing: 1% of stake
- Delegators may undelegate
- Reputation damage

**Best Practice**: Use monitoring tools and automated failover.
```bash
# Setup monitoring
citrate validator monitor --alert-email your@email.com

# Automated failover
citrate validator failover --backup-node backup.yourdomain.com
```

### Can I run a validator on cloud providers?

**Yes!** Most validators run on AWS, GCP, or dedicated providers.

**Recommended Setups**:

**AWS**:
- Instance: `c5.4xlarge` (16 vCPU, 32 GB RAM)
- Storage: 1 TB `gp3` EBS
- GPU (optional): `p3.2xlarge` (NVIDIA V100)
- Cost: ~$300/month (CPU-only), ~$3,500/month (with GPU)

**GCP**:
- Instance: `n2-standard-16` (16 vCPU, 64 GB RAM)
- Storage: 1 TB SSD persistent disk
- GPU (optional): `a2-highgpu-1g` (NVIDIA A100)
- Cost: ~$350/month (CPU-only), ~$4,000/month (with GPU)

**Dedicated Providers** (recommended):
- **Latitude.sh**: ~$200/month bare metal
- **Hetzner**: ~$150/month dedicated servers
- **OVH**: ~$180/month dedicated servers

**Important**: Ensure low latency (<100 ms to other validators). Use regions with good connectivity to North America, Europe, and Asia.

### Do I need a GPU?

**Required**: No
**Recommended**: Yes (for AI inference bonuses)

**Without GPU**:
- Can still produce blocks and earn base rewards
- Miss out on inference bonuses (~20-30% extra rewards)

**With GPU**:
- Earn +1% per inference execution in your blocks
- Average 20-50 inferences per block during active usage
- Bonus: +20-50% on block rewards

**Minimum GPU**:
- NVIDIA RTX 3090 (24 GB VRAM)
- Can run models up to 20B parameters

**Recommended GPU**:
- NVIDIA A100 (40 GB or 80 GB VRAM)
- Can run models up to 70B parameters
- Future-proof for larger models

**Cost-Benefit**:
```
GPU Cost: ~$3,000/month (A100 on cloud)
Extra rewards: +30% on block rewards
Base monthly earnings: $1,555
With GPU: $1,555 * 1.30 = $2,022
Extra income: $467/month

ROI: Negative on cloud, positive if you own hardware
```

**Recommendation**: Start CPU-only, add GPU if AI inference becomes popular.

---

## For AI Researchers

### How do I monetize my AI models?

**Deploy your model to Citrate** and earn fees every time someone uses it.

**Revenue Model**:
```
User pays inference fee ‚Üí Split:
- 70% to you (model owner)
- 20% to validator (who ran the inference)
- 10% to protocol treasury
```

**Pricing Models**:

**1. Pay-Per-Inference**:
```solidity
accessPolicy: {
  type: "pay-per-inference",
  pricePerToken: 0.0001 LATT  // You set the price
}
```

**2. Subscription**:
```solidity
accessPolicy: {
  type: "subscription",
  monthlyFee: 100 LATT
}
```

**3. Free (Open Source)**:
```solidity
accessPolicy: {
  type: "public",
  price: 0
}
// You can still earn tips from grateful users
```

**Example Earnings**:
```
Model: Llama 3 70B fine-tuned for legal analysis
Price: 0.0005 LATT per token
Usage: 10 million tokens per month

Monthly revenue:
10,000,000 tokens * 0.0005 LATT/token * 0.70 (your share)
= 3,500 LATT/month
= $3,500/month at $1/LATT
= $35,000/month at $10/LATT
```

### Can I keep my model weights private?

**Yes!** Citrate supports **private models** with cryptographic access control.

**Option 1: Encrypted Weights**:
```typescript
// Encrypt weights before uploading to IPFS
const encryptedWeights = encrypt(weights, yourSecretKey);
const ipfsCID = await uploadToIPFS(encryptedWeights);

// Register model
await registry.deployModel({
  weights: ipfsCID,
  encryption: {
    algorithm: "AES-256-GCM",
    accessControl: "subscription"  // Only paying subscribers get decryption key
  }
});
```

**Option 2: Trusted Execution Environment (TEE)**:
```
Validators run inference inside Intel SGX or AMD SEV enclaves
Weights are decrypted only inside enclave (hardware-protected)
Even validator operator cannot see weights
```

**Option 3: Multi-Party Computation (MPC)** (future):
```
Model weights split across multiple validators
Inference runs collaboratively without any single party seeing full weights
Slower but maximum privacy
```

### How do I update my model?

**Versioning is built-in**:
```typescript
// Deploy version 1.0
const v1 = await registry.deployModel({
  weights: "QmVersion1...",
  version: "1.0.0"
});

// Later: deploy version 1.1 with improved weights
const v1_1 = await registry.updateModel({
  modelId: v1.id,
  weights: "QmVersion1_1...",
  version: "1.1.0",
  changelog: "Improved accuracy on medical queries"
});

// Users can specify version:
await client.inference.run({
  model: v1.id,
  version: "1.1.0",  // Or "latest"
  input: "..."
});
```

**Backward Compatibility**:
- Old versions remain accessible (immutable on IPFS)
- Users can pin to specific version if needed
- Default: use latest version

### Can I collaborate with other researchers?

**Yes!** Use **federated learning** to train models collaboratively.

**Workflow**:
```typescript
// Create federated learning job
const job = await federatedLearning.createJob({
  baseModel: "llama-3-70b",
  task: "medical-diagnosis",
  dataset: "ipfs://QmMedicalDataSpec...",  // Dataset specification (not actual data)
  minContributors: 100,
  reward: 10000  // 10,000 LATT split among contributors
});

// Contributors train locally on their private data
await job.submitGradient({
  gradient: localGradient,  // Computed on your private data
  proof: zkProof  // Proves you trained correctly without revealing data
});

// After 100 contributions, aggregated model is published
const improvedModel = await job.finalizeModel();
// All contributors earn rewards proportional to their contribution quality
```

**Use Cases**:
- **Medical AI**: Hospitals train on patient data without sharing records
- **Financial Models**: Banks train fraud detection without sharing transactions
- **Personal Assistants**: Users improve models while keeping conversations private

### What about LoRA adapters?

**LoRA (Low-Rank Adaptation)** is fully supported and **highly recommended** for efficient fine-tuning.

**Why LoRA?**
- Fine-tune 70B model with only **100 MB adapter** (vs. 140 GB full weights)
- Cheap to store and distribute on-chain
- Can mix and match: `base_model + adapter_A + adapter_B`

**Deploy a LoRA adapter**:
```typescript
const lora = await loraFactory.createLoRA({
  baseModel: "llama-3-70b",
  dataset: "ipfs://QmMyDataset...",
  rank: 16,
  alpha: 32,
  targetModules: ["q_proj", "v_proj"]  // Which layers to adapt
});

// Inference automatically combines base + adapter
const result = await client.inference.run({
  model: lora.id,
  input: "Your specialized query"
});
```

**Marketplace**:
- Base models are expensive to train but reusable
- LoRA adapters are cheap to create and highly specialized
- Users pay for base model + adapter combination
- You earn fees on your adapter

**Example**:
```
Base model: Llama 3 70B (general purpose)
Your adapter: Legal contract analysis
User query: "Summarize this employment contract"

Inference uses: Llama 3 70B + your legal adapter
Revenue split:
- 50% to base model owner
- 50% to adapter owner (you)
```

---

## Economics & Tokenomics

### What is the LATT token?

**LATT** (Citrate native token) has three functions:

1. **Gas fees**: Pay for transactions and AI inference
2. **Staking**: Validators stake LATT to earn block rewards
3. **Governance**: Vote on protocol upgrades and parameter changes

**Total Supply**: 1,000,000,000 LATT (fixed, no inflation beyond tail emission)

**Distribution**:
- 50% Mining rewards (10-year emission)
- 25% Ecosystem fund (grants, partnerships)
- 15% Team & advisors (4-year vest with 1-year cliff)
- 10% Treasury (protocol operations)

### How do I acquire LATT tokens?

**Before Mainnet Launch**:
- Private sale (for accredited investors)
- Public sale (token generation event)
- Testnet faucet (free testnet tokens for development)

**After Mainnet Launch**:
- Exchanges (CEX and DEX)
- Earn by running a validator
- Earn by deploying popular AI models
- Earn by contributing to federated learning jobs

**No ICO**: Citrate uses a fair launch model with gradual emission.

### What's the emission schedule?

**Block Rewards**:
```
Blocks 0 - 2,100,000:       10 LATT per block (first ~4 years)
Blocks 2,100,001 - 4,200,000: 5 LATT per block (years 5-8)
Blocks 4,200,001 - 6,300,000: 2.5 LATT per block (years 9-12)
Blocks 6,300,001+:            0.1 LATT per block (perpetual tail emission)
```

**Total Emission**:
```
First 4 years:  21,000,000 blocks * 10 LATT = 210,000,000 LATT
Next 4 years:   21,000,000 blocks * 5 LATT = 105,000,000 LATT
Next 4 years:   21,000,000 blocks * 2.5 LATT = 52,500,000 LATT
Next 4 years:   21,000,000 blocks * 1.25 LATT = 26,250,000 LATT
...
Total after 10 years: ~500,000,000 LATT (matches allocation)
```

**Tail Emission**: 0.1 LATT per block forever (to ensure validator incentives don't go to zero).

### What's the expected LATT price?

**We don't speculate on price**, but here's a valuation framework:

**Comparable Projects**:
| Project | Market Cap | Token Price | Use Case |
|---------|-----------|-------------|----------|
| Ethereum | $200B | $1,600 | Smart contracts |
| Solana | $20B | $50 | High-performance smart contracts |
| ICP | $3B | $6 | Decentralized compute |
| Kaspa | $2B | $0.10 | High-throughput currency |

**Citrate Value Drivers**:
1. AI inference volume (more usage = more fees = more LATT burned = deflationary)
2. Model marketplace GMV (gross merchandise value)
3. Total value locked in DeFi (Citrate-based lending, DEXs, etc.)
4. Validator staking (more staked = less circulating supply)

**Hypothetical Scenario** (not financial advice):
```
If Citrate captures:
- 1% of AI inference market ($200M/year)
- 0.1% of DeFi TVL ($1B locked)
- 10,000 validators staking 30M LATT total

Then:
Circulating supply: 250M LATT (after 4 years, excluding staked)
Revenue: $200M/year
Revenue multiple: 10x (typical for growth tech)
Market cap: $2B
Token price: $2B / 250M = $8/LATT

Note: This is purely illustrative, not a price prediction.
```

### Is LATT deflationary?

**Yes, partially.**

**Burn Mechanisms**:
1. **Transaction fees**: 20% of all fees are burned
2. **Slashing**: Penalized validator stakes are burned
3. **Model registry fees**: 10% of registration fees are burned

**Emission**:
- Block rewards add new supply
- Emission decreases over time (halvings)
- Perpetual tail emission (0.1 LATT/block) to sustain validators

**Net Effect**:
- **Early years**: Inflationary (emission > burn)
- **Later years**: Potentially deflationary (burn > tail emission)
- Depends on network usage (high usage = more burns)

**Example**:
```
Year 10+ (tail emission):
New supply: 0.1 LATT * 15,768,000 blocks/year = 1,576,800 LATT/year

If network processes 1M transactions/day:
Fees: 1M tx * 0.001 LATT/tx * 365 days = 365,000 LATT/year
Burned: 365,000 * 0.20 = 73,000 LATT/year

Net: +1,503,800 LATT/year (~0.15% inflation)

If network processes 10M transactions/day:
Burned: 3,650,000 * 0.20 = 730,000 LATT/year
Net: +846,800 LATT/year (~0.08% inflation)

If network processes 50M transactions/day:
Burned: 18,250,000 * 0.20 = 3,650,000 LATT/year
Net: -2,073,200 LATT/year (~0.2% deflation)
```

**High usage ‚Üí deflationary pressure ‚Üí token appreciation (in theory).**

---

## Security & Privacy

### Is Citrate secure?

Citrate employs **defense-in-depth** security:

**Consensus Security**:
- GhostDAG proven secure if <50% Byzantine
- BFT checkpoints require 2/3+ honest committee
- VRF-based leader election (prevents manipulation)

**Execution Security**:
- EVM compatibility = battle-tested security model
- All standard Ethereum defenses (reentrancy guards, SafeMath, etc.)
- AI precompiles sandboxed (cannot access validator file system)

**Cryptographic Security**:
- Ed25519 signatures (RFC 8032 standard)
- ECDSA (secp256k1, same as Bitcoin/Ethereum)
- SHA3-256 (Keccak) for hashing
- ZK proofs (PLONK, Groth16, STARKs)

**Network Security**:
- Sybil resistance via staking
- DDoS mitigation (rate limiting, peer limits)
- Eclipse attack prevention (diverse peer discovery)

**Audits**:
- ‚úÖ Consensus layer audited by [Security Firm]
- ‚úÖ Execution layer audited by [Security Firm]
- ‚úÖ Smart contracts audited by OpenZeppelin
- ‚è≥ Formal verification in progress

### Has Citrate been audited?

**Yes**:
- Consensus layer: Audited by [Security Firm] (report: https://audits.citrate.ai/consensus-2024.pdf)
- Execution layer: Audited by [Security Firm] (report: https://audits.citrate.ai/execution-2024.pdf)
- Smart contracts: Audited by OpenZeppelin (report: https://audits.citrate.ai/contracts-2024.pdf)

**Formal Verification**:
- Governance contracts: ‚úÖ Verified with Certora
- ModelRegistry: ‚è≥ In progress
- LoRAFactory: ‚è≥ Planned

**Bug Bounty**:
- Critical: Up to $100,000
- High: Up to $50,000
- Medium: Up to $10,000
- Program: https://bugbounty.citrate.ai

### Can validators steal my AI models?

**No**, for multiple reasons:

**1. Models are content-addressed (IPFS)**:
- Anyone can access the model weights (they're on IPFS)
- The **value** is in the on-chain metadata and reputation

**2. Access control is enforced**:
```solidity
// If model is private or pay-per-use:
function runInference(ModelId id, bytes input) external payable {
    require(checkAccess(id, msg.sender), "Access denied");
    // Payment required before validator can run inference
}
```

**3. Encrypted models** (optional):
- Encrypt weights before uploading
- Only paying users get decryption key
- Validator runs inference in TEE (encrypted memory)

**4. Reputation system**:
- Validators who cheat (wrong outputs, censorship) get slashed
- Users can verify inference outputs via ZK proofs

**Worst Case**: Validator could copy your public model and redeploy it. But:
- Your original model has on-chain provenance and reputation
- Users will prefer established, verified models
- Community can flag copycats

**Best Practice**: Use encrypted weights or LoRA adapters (harder to steal).

### Is my data private when using AI inference?

**It depends on your threat model**:

**Default (No Privacy)**:
- Inputs and outputs are **not private** from the validator running inference
- Validator sees your prompts and model responses
- Similar to using OpenAI API (they see your prompts too)

**Privacy Options**:

**1. Trusted Validators**:
- Choose validators with good reputation
- Validators stake tokens (risk slashing if they leak data)

**2. Trusted Execution Environments (TEE)**:
- Inference runs inside Intel SGX or AMD SEV enclave
- Even validator operator cannot see inputs/outputs
- Cryptographic attestation proves TEE was used

**3. Zero-Knowledge Inference** (future):
- Fully homomorphic encryption (FHE) allows computation on encrypted data
- Validator never sees plaintext
- Very slow (100-1000x overhead)

**4. Multi-Party Computation (MPC)** (future):
- Split inference across multiple validators
- No single validator sees full input or output
- Requires coordination (slower)

**Recommendation**:
- Non-sensitive queries: Use default (fast, cheap)
- Sensitive queries: Use TEE (moderate overhead)
- Highly sensitive: Wait for ZK/MPC (future)

### What if Citrate gets attacked?

**Citrate has multiple layers of defense**:

**51% Attack** (attacker controls >50% of stake):
- **Cost**: Must acquire 500M+ LATT (~$500M+ at $1/LATT)
- **Detection**: Community notices unusual voting patterns
- **Response**: Social consensus forks to exclude attacker
- **Outcome**: Attacker loses stake in the fork (economic loss)

**Censorship Attack**:
- **GhostDAG includes all blocks** (even from censored validators)
- Maximum censorship delay: ~12 seconds (time to finality)
- Repeated censorship can be penalized via governance

**Sybil Attack** (create many fake validators):
- **Defense**: Staking requirement (10,000 LATT minimum)
- Creating 1000 fake validators costs 10M LATT
- Doesn't increase attack power (voting is stake-weighted, not count-weighted)

**Smart Contract Bugs**:
- **Defense**: Audits, formal verification, bug bounties
- **Response**: Governance can upgrade contracts (with time-lock delay)
- **Last Resort**: Social consensus hard fork (if catastrophic)

**Long-Range Attack** (rewrite history):
- **Defense**: Checkpoints every 100,000 blocks
- Clients reject chains diverging before latest checkpoint
- Cannot rewrite checkpointed history even with 100% of old stake

**DDoS**:
- **Defense**: Rate limiting, peer limits, mempool size caps
- Validators distributed globally (hard to target all)
- Network degradation (slower blocks) but not full outage

---

## Roadmap & Future

### When is mainnet launch?

**Current Phase**: Testnet (public since Q4 2024)

**Roadmap**:
- ‚úÖ **Phase 1**: Consensus + execution (completed)
- ‚úÖ **Phase 2**: Core infrastructure (completed)
- ‚úÖ **Phase 3**: Developer tools (completed)
- üöß **Phase 4**: Model marketplace (in progress, Week 3)
- üìÖ **Phase 5**: Advanced features (Q1 2025)
- üìÖ **Phase 6**: Mainnet launch (Q2 2025)

**Mainnet Prerequisites**:
1. ‚úÖ Testnet running stably for 6+ months
2. ‚è≥ 3 independent security audits completed
3. ‚è≥ Bug bounty program (3 months, no critical bugs)
4. ‚è≥ Validator onboarding (100+ independent validators)
5. ‚è≥ Governance framework tested
6. ‚è≥ Emergency pause mechanism tested

**Timeline**: Targeting **April-June 2025** for mainnet genesis.

### What's coming in Phase 5?

**Advanced Features (Q1 2025)**:

1. **Federated Learning Framework**:
   - Train models collaboratively without sharing data
   - ZK proofs of correct training
   - Automated reward distribution

2. **Cross-Chain Bridges**:
   - Ethereum bridge (lock LATT, mint wLATT on Ethereum)
   - Cosmos IBC integration
   - Bitcoin atomic swaps (HTLCs)

3. **Privacy Features**:
   - Confidential transactions (hide amounts)
   - ZK inference (encrypted inputs/outputs)
   - Private model weights (TEE support)

4. **LoRA at Scale**:
   - Automated LoRA training jobs
   - Adapter marketplace
   - Dynamic adapter composition

5. **Optimistic Rollups** (Layer 2):
   - High-frequency inference (10x throughput)
   - Lower fees for experimentation
   - Fraud proofs for security

### Will Citrate support [insert feature]?

**Likely "Yes" if it fits our vision**:
- AI/ML-related features
- Scaling improvements (sharding, Layer 2s)
- Privacy enhancements (ZK, MPC)
- Developer tools and SDKs
- Cross-chain interoperability

**Likely "No" if it diverges from core mission**:
- Features unrelated to AI or smart contracts
- Changes that compromise decentralization
- Breaking EVM compatibility

**Governance decides**: Token holders vote on major protocol changes.

**Request a Feature**: https://github.com/citrate-ai/citrate/discussions

### Can I contribute to Citrate?

**Yes! Citrate is open-source** (Apache 2.0 license).

**Ways to Contribute**:

1. **Code**:
   - GitHub: https://github.com/citrate-ai/citrate
   - Issues: https://github.com/citrate-ai/citrate/issues
   - PRs welcome (check CONTRIBUTING.md)

2. **Documentation**:
   - Improve docs, write tutorials
   - Translate to other languages

3. **Testing**:
   - Run testnet nodes, report bugs
   - Security testing (bug bounty)

4. **Ecosystem**:
   - Build dapps on Citrate
   - Deploy AI models
   - Create developer tools

5. **Community**:
   - Answer questions on Discord
   - Write blog posts, create videos
   - Organize meetups and hackathons

**Grants Available**: Apply at https://grants.citrate.ai

### Is there a DAO?

**Yes, Citrate governance is decentralized**:

**Governance Token**: LATT (1 LATT = 1 vote)

**What Can Be Governed**:
- Protocol parameters (k, max_parents, gas prices)
- Treasury spending (ecosystem fund allocation)
- Protocol upgrades (consensus changes, new precompiles)
- Emergency actions (pause network, fix critical bugs)

**Proposal Process**:
1. Submit proposal (requires 100,000 LATT deposit)
2. Discussion period (7 days)
3. Voting period (14 days)
4. Execution (if >50% yes votes and 10% quorum)

**Delegation**:
- Delegate voting power to representatives
- Non-custodial (you keep your tokens)
- Can change delegation anytime

**Current Governance**: Foundation-led (until mainnet launch), then progressively decentralized.

---

## Getting Help

### Where can I get support?

**Documentation**: https://docs.citrate.ai
**Discord**: https://discord.gg/citrate (most active)
**Telegram**: https://t.me/citrate
**Twitter**: @CitrateAI
**GitHub Discussions**: https://github.com/citrate-ai/citrate/discussions
**Email**: hello@citrate.ai (non-urgent)

**For Developers**:
- Developer Discord channel: #dev-support
- Stack Overflow: Tag questions with `citrate`

**For Validators**:
- Validator Telegram: https://t.me/citrate-validators
- Validator docs: https://docs.citrate.ai/validators

**For Security Issues**:
- **DO NOT** disclose publicly
- Email: security@citrate.ai (PGP key: https://citrate.ai/pgp)

### How do I report a bug?

**Non-Security Bugs**:
- GitHub Issues: https://github.com/citrate-ai/citrate/issues
- Include: Citrate version, OS, reproduction steps, error logs

**Security Bugs**:
- Email: security@citrate.ai
- Include: Detailed description, reproduction steps, PoC code
- Eligible for bug bounty (up to $100,000)

**Response Time**:
- Critical bugs: <4 hours
- High severity: <24 hours
- Medium severity: <3 days
- Low severity: <7 days

### Where can I learn more?

**Essential Reading**:
- White Paper: https://citrate.ai/whitepaper.pdf
- Documentation: https://docs.citrate.ai
- GitHub: https://github.com/citrate-ai/citrate

**Tutorials**:
- Getting Started: https://docs.citrate.ai/getting-started
- Deploy Your First Model: https://docs.citrate.ai/deploy-model
- Build a dapp: https://docs.citrate.ai/tutorials/dapp

**Videos**:
- YouTube: https://youtube.com/@citrate-ai
- Intro to Citrate (10 min): [Link]
- Technical Deep Dive (45 min): [Link]

**Research Papers**:
- GhostDAG: Sompolinsky & Zohar (2018)
- Model Context Protocol: Anthropic (2024)
- Citrate Architecture: [Link to paper]

**Community**:
- Discord: https://discord.gg/citrate
- Twitter: @CitrateAI
- Reddit: r/citrate

---

## Still Have Questions?

**Join our Discord**: https://discord.gg/citrate

Our community and core team are happy to help!

---

*Last Updated: October 27, 2025*
*For the latest version, visit: https://docs.citrate.ai/faq*
